{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set_style('white')  # plot formatting\n",
    "from scipy import stats\n",
    "##sklearn modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Manage our Data  \n",
    "adult = pd.read_csv(\"adult.data\",header=None) ##index 14 = label\n",
    "letter = pd.read_csv(\"letter-recognition.data\", header=None) #index 0 = label\n",
    "covtype = pd.read_csv(\"covtype.data\", header=None) #index 54 = label\n",
    "bank = pd.read_csv(\"bank.csv\",header=None,sep=';',skiprows=1)\n",
    "default = pd.read_excel(\"default.xls\",skiprows=1)\n",
    "##reassign lables according to Caruana Mizil\n",
    "##covtype 7 is the positive class denoted by 1, and all else are denoted 0\n",
    "covtype[54] = covtype[54].replace([2,3,4,5,6,7],0)\n",
    "covtype[54] = covtype[54].replace(1,1)\n",
    "##all letters a-m = 1 and others are 0\n",
    "letter = letter.replace(['A','B','C','D','E','F','G','H','I','J','K','L','M'],1)\n",
    "letter = letter.replace(['N','O','P','Q','R','S','T','U','V','W','X','Y','Z'],0)\n",
    "##>50K == 1 , less than or equal == 0\n",
    "##adult = adult.replace([\" <=50K\",\" >50K\"],[0,1])\n",
    "adult = pd.get_dummies(adult)\n",
    "##bank  column 52 == yes\n",
    "bank = pd.get_dummies(bank)\n",
    "\n",
    "##split data into X and Y\n",
    "X = [adult.iloc[:,:107],covtype.iloc[:,:53],letter.iloc[:,1:],bank.iloc[:,:51], default.iloc[:,:23]]\n",
    "Y = [adult.iloc[:,109],covtype.iloc[:,54],letter.iloc[:,0],bank.iloc[:,52], default.iloc[:,24]]\n",
    "\n",
    "##Initialize the classifiers according to CM06\n",
    "clf1 = LogisticRegression(multi_class='multinomial',\n",
    "                          solver='newton-cg',\n",
    "                          random_state=1)\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',\n",
    "                            leaf_size=50)\n",
    "clf3 = SVC(random_state=1)\n",
    "\n",
    "clf4 = RandomForestClassifier(n_estimators = 1024)\n",
    "\n",
    "clf5 = MLPClassifier(max_iter = 750)\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf2)])\n",
    "\n",
    "pipe3 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf3)])\n",
    "\n",
    "pipe4 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf4)])\n",
    "\n",
    "pipe5 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf5)])\n",
    "\n",
    "# Setting up the parameter grids according to CM06\n",
    "param_grid1 = [{'classifier__penalty': ['l2'],\n",
    "                'classifier__C': np.power(10., np.arange(-4, 8))}]\n",
    "\n",
    "param_grid2 = [{'classifier__n_neighbors': [round(x) for x in list(np.logspace(np.log10(1), np.log10(500), num=25))],\n",
    "                'classifier__p': [2]}]  ##p == 2 means using euclidean distance\n",
    "\n",
    "param_grid3 = [{'classifier__kernel': ['rbf'],\n",
    "                'classifier__C': np.power(10., np.arange(-7, 3)),\n",
    "                'classifier__gamma': list([0.001,0.005,0.01,0.05,0.1,0.5,1,2])},\n",
    "               {'classifier__kernel': ['poly'],\n",
    "                'classifier__C': np.power(10., np.arange(-7, 3)),\n",
    "                'classifier__gamma': list([2,3])},\n",
    "               {'classifier__kernel': ['linear'],\n",
    "                'classifier__C': np.power(10., np.arange(-7, 3))}]\n",
    "\n",
    "param_grid4 = [{'classifier__max_features': [1,2,4,6,8,12,15]}]\n",
    "\n",
    "param_grid5 = [{'classifier__hidden_layer_sizes': [1,2,4,8,32,128],\n",
    "                'classifier__momentum': [0,.2,.5,.9]}]\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4, param_grid5),\n",
    "                            (pipe1, pipe2, pipe3, pipe4, pipe5),\n",
    "                            ('Logistic', 'KNN', 'SVM', 'RF', 'ANN')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1,\n",
    "                       cv=2, # just 2-fold inner loop, i.e. train/test\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifiers(xData,yData,numTrials):\n",
    "    \n",
    "    for i in range(numTrials):\n",
    "        print(\"Trial {}\".format(i+1))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(xData,yData,train_size=5000,random_state=i,stratify=yData)\n",
    "        \n",
    "        cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n",
    "\n",
    "        skfold = StratifiedKFold( n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "        # The outer loop for algorithm selection\n",
    "        c = 1\n",
    "        for outer_train_idx, outer_valid_idx in skfold.split(X_train,y_train):\n",
    "            for name, gs_est in sorted(gridcvs.items()):\n",
    "                print('outer fold %d/5 | tuning %-8s' % (c, name), end='')\n",
    "\n",
    "                # The inner loop for hyperparameter tuning\n",
    "                gs_est.fit(X_train.iloc[outer_train_idx], y_train.iloc[outer_train_idx])\n",
    "                y_pred = gs_est.predict(X_train.iloc[outer_valid_idx])\n",
    "                acc = accuracy_score(y_true=y_train.iloc[outer_valid_idx], y_pred=y_pred)\n",
    "                print(' | inner ACC %.2f%% | outer ACC %.2f%%' %\n",
    "                      (gs_est.best_score_ * 100, acc * 100))\n",
    "                cv_scores[name].append(acc)\n",
    "\n",
    "            c += 1\n",
    "        \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSummary(name,xData,yData):\n",
    "    print(\"Results for {}\".format(name))\n",
    "    best_algo = gridcvs[name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xData,yData,train_size=5000,random_state=6,stratify=yData)\n",
    "    best_algo.fit(X_train,y_train)\n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "    test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "    print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "          (100 * best_algo.best_score_))\n",
    "    print('Best Parameters: %s' % gridcvs[name].best_params_)\n",
    "    print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "    print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataset(nameData,x,y,numtrials):\n",
    "    cv = testClassifiers(x,y,numtrials)\n",
    "    \n",
    "    bestMean = 0\n",
    "    bestName = None\n",
    "\n",
    "    print(\"\\nResults on {} data\\n\".format(nameData))\n",
    "    for name in cv:\n",
    "        if np.mean(cv[name]) > bestMean:\n",
    "            bestMean = np.mean(cv[name])\n",
    "            bestName = name\n",
    "        print('%-8s | outer CV acc. %.2f%% +\\- %.3f' % (\n",
    "              name, 100 * np.mean(cv[name]), 100 * np.std(cv[name])))\n",
    "    print()\n",
    "    for name in cv:\n",
    "        print('{} best parameters'.format(name), gridcvs[name].best_params_)\n",
    "\n",
    "    print()\n",
    "    for name in cv:\n",
    "        GenerateSummary(name,x,y)\n",
    "        print('')\n",
    "\n",
    "    for name in cv:\n",
    "        t,p = stats.ttest_ind(cv[bestName],cv[name],equal_var=False)\n",
    "        print('p:{} \\nt:{} \\nFor {}\\nComparing against {}\\n'.format(p,t,name,bestName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDataset(\"COV\",X[1],Y[1],3)\n",
    "TestDataset(\"LETTERS\",X[2],Y[2],3)\n",
    "TestDataset(\"ADULT\",X[0],Y[0],3)\n",
    "TestDataset(\"BANK\",X[3],Y[3],3)\n",
    "TestDataset(\"DEFAULT\",X[4],Y[4],3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
